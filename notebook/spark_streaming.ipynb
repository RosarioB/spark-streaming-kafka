{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44948af3-c373-42b2-a087-76815574cefd",
   "metadata": {},
   "source": [
    "## Download the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b5075-4c36-4467-87fb-545a4a57ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf jars\n",
    "!mkdir jars\n",
    "!wget -q -P jars https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.4.1/spark-sql-kafka-0-10_2.12-3.4.1.jar\n",
    "!wget -q -P jars https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.1/kafka-clients-3.5.1.jar\n",
    "!wget -q -P jars https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.4.1/spark-token-provider-kafka-0-10_2.12-3.4.1.jar\n",
    "!wget -q -P jars https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.18/scala-library-2.12.18.jar\n",
    "!wget -q -P jars https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb860b0-309f-45bc-8322-44b45cce6a4a",
   "metadata": {},
   "source": [
    "## Set up SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ad2104-8d35-4c5b-bbbb-b0889488ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d768247-b703-498f-a03b-e304fc822535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupiter-pyspark:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Structured Streaming example with Kafka</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff8baf3190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = os.getcwd() + '/jars'\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "        .master('local[*]')\n",
    "        .appName('Spark Structured Streaming example with Kafka')\n",
    "        .config(\"spark.jars\", \n",
    "                base_dir + '/kafka-clients-3.5.1.jar' + \",\" + \n",
    "                base_dir +'/spark-sql-kafka-0-10_2.12-3.4.1.jar' + \",\" + \n",
    "                base_dir + '/spark-token-provider-kafka-0-10_2.12-3.4.1.jar' + \",\" + \n",
    "                base_dir + '/scala-library-2.12.18.jar' + \",\" + \n",
    "                base_dir + '/commons-pool2-2.11.1.jar')\n",
    "        .getOrCreate())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4a7c6-7391-4eb2-9597-2eac9975b788",
   "metadata": {},
   "source": [
    "## Define the schema for our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74832419-96d2-4ee6-8208-a7a6ff04084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b373b13f-6b71-43e1-bff5-904daa6bf258",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"VP\", StructType([\n",
    "      StructField(\"desi\", StringType()),\n",
    "      StructField(\"dir\", StringType()),\n",
    "      StructField(\"oper\", IntegerType()),\n",
    "      StructField(\"veh\", IntegerType()),\n",
    "      StructField(\"tst\", TimestampType()),\n",
    "      StructField(\"tsi\", LongType()),\n",
    "      StructField(\"spd\", DoubleType()),\n",
    "      StructField(\"hdg\", IntegerType()),\n",
    "      StructField(\"lat\", DoubleType()),\n",
    "      StructField(\"long\", DoubleType()),\n",
    "      StructField(\"acc\", DoubleType()),\n",
    "      StructField(\"dl\", IntegerType()),\n",
    "      StructField(\"odo\", StringType()),\n",
    "      StructField(\"drst\", StringType()),\n",
    "      StructField(\"oday\", DateType()),\n",
    "      StructField(\"jrn\", IntegerType()),\n",
    "      StructField(\"line\", IntegerType()),\n",
    "      StructField(\"start\", StringType()),\n",
    "      StructField(\"loc\", StringType()),\n",
    "      StructField(\"stop\", LongType()),\n",
    "      StructField(\"route\", StringType()),\n",
    "      StructField(\"occu\", IntegerType())\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b0670-ce5e-4bbd-8c9d-403ecab5b927",
   "metadata": {},
   "source": [
    "## Initialize the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd14eab-fc5e-4491-96ed-3bd85d615858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689de19d-1a25-4ade-a106-7002b352a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (spark.readStream\n",
    "            .format(\"kafka\")\n",
    "            .option(\"kafka.bootstrap.servers\", \"broker:29092\") # localhost:9092 local, broker:29092 docker\n",
    "            .option(\"subscribe\", \"vehicle-positions\")\n",
    "            .option(\"startingOffsets\", \"earliest\")\n",
    "            .load()\n",
    "            .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06399f1c-c1a0-41e8-beba-65ac66764f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32823566-2fa6-4fe3-8870-523e97c7278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = (lines\n",
    "    .select(from_json(col(\"value\"), schema).alias(\"json\")) \n",
    "    .select(\"json.VP.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ab8ac7-d923-4b1f-8402-7b5371911cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- desi: string (nullable = true)\n",
      " |-- dir: string (nullable = true)\n",
      " |-- oper: integer (nullable = true)\n",
      " |-- veh: integer (nullable = true)\n",
      " |-- tst: timestamp (nullable = true)\n",
      " |-- tsi: long (nullable = true)\n",
      " |-- spd: double (nullable = true)\n",
      " |-- hdg: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- acc: double (nullable = true)\n",
      " |-- dl: integer (nullable = true)\n",
      " |-- odo: string (nullable = true)\n",
      " |-- drst: string (nullable = true)\n",
      " |-- oday: date (nullable = true)\n",
      " |-- jrn: integer (nullable = true)\n",
      " |-- line: integer (nullable = true)\n",
      " |-- start: string (nullable = true)\n",
      " |-- loc: string (nullable = true)\n",
      " |-- stop: long (nullable = true)\n",
      " |-- route: string (nullable = true)\n",
      " |-- occu: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883102b-f38d-4727-beca-1961244d33e1",
   "metadata": {},
   "source": [
    "## Perform streaming transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f8ad5e9-0b0b-4847-91c4-0cc1b4b4aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (select.groupBy(\n",
    "        window(col(\"tst\"), \"10 minutes\", \"10 minutes\"),\n",
    "        col(\"route\")\n",
    "      ).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3828bc2b-1772-429e-a919-7da4bb75f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- route: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ce1da-1f75-4fc1-9b18-c885daa704c9",
   "metadata": {},
   "source": [
    "## Start the streaming query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc51ac-7ece-4b27-91b7-bde3b2c34cf5",
   "metadata": {},
   "source": [
    "### Append mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c391bd-bff9-428d-8601-fcd55721ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_append = (df.writeStream\n",
    "            .format(\"memory\")\n",
    "            .outputMode(\"update\")\n",
    "            .queryName(\"query_append\")\n",
    "            .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b1e7388-dabc-4902-9a6e-523602004fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+-----+\n",
      "|window                                    |route|count|\n",
      "+------------------------------------------+-----+-----+\n",
      "|{2023-08-04 12:30:00, 2023-08-04 12:40:00}|2113 |16   |\n",
      "|{2023-08-04 12:50:00, 2023-08-04 13:00:00}|2113 |533  |\n",
      "|{2023-08-04 13:00:00, 2023-08-04 13:10:00}|2113 |104  |\n",
      "|{2023-08-04 13:10:00, 2023-08-04 13:20:00}|2113 |35   |\n",
      "|{2023-08-04 12:40:00, 2023-08-04 12:50:00}|2113 |169  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |30   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |64   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |96   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |126  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |154  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |181  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |189  |\n",
      "+------------------------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql(\"select * from query_append \")\n",
    "    .filter(col('route') == '2113')\n",
    "    .show(n = 100, truncate = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10c10e3-a06f-4049-b76d-853b55b36436",
   "metadata": {},
   "source": [
    "### Complete mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89e98d29-4549-404f-9979-6af12fd09bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_complete = (df.writeStream\n",
    "            .format(\"memory\")\n",
    "            .outputMode(\"complete\")\n",
    "            .queryName(\"query_complete\")\n",
    "            .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708df364-af90-40f7-bf04-2ab94e9d5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+-----+\n",
      "|window                                    |route|count|\n",
      "+------------------------------------------+-----+-----+\n",
      "|{2023-08-04 12:30:00, 2023-08-04 12:40:00}|2113 |16   |\n",
      "|{2023-08-04 12:50:00, 2023-08-04 13:00:00}|2113 |533  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |189  |\n",
      "|{2023-08-04 13:00:00, 2023-08-04 13:10:00}|2113 |104  |\n",
      "|{2023-08-04 13:10:00, 2023-08-04 13:20:00}|2113 |35   |\n",
      "|{2023-08-04 12:40:00, 2023-08-04 12:50:00}|2113 |169  |\n",
      "+------------------------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql(\"select * from query_complete \")\n",
    "    .filter(col('route') == '2113')\n",
    "    .show(n = 100, truncate = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a4ca0-6eb1-4c32-a3ef-1dd82d91737e",
   "metadata": {},
   "source": [
    "### Update mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4c04dc-4a7e-4804-b9e9-a7e88a1ad9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_update = (df.writeStream\n",
    "            .format(\"memory\")\n",
    "            .outputMode(\"update\")\n",
    "            .queryName(\"query_update\")\n",
    "            .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "709680e7-85df-4915-a42c-7f58840bc31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+-----+\n",
      "|window                                    |route|count|\n",
      "+------------------------------------------+-----+-----+\n",
      "|{2023-08-04 12:30:00, 2023-08-04 12:40:00}|2113 |16   |\n",
      "|{2023-08-04 12:50:00, 2023-08-04 13:00:00}|2113 |533  |\n",
      "|{2023-08-04 13:00:00, 2023-08-04 13:10:00}|2113 |104  |\n",
      "|{2023-08-04 13:10:00, 2023-08-04 13:20:00}|2113 |35   |\n",
      "|{2023-08-04 12:40:00, 2023-08-04 12:50:00}|2113 |169  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |18   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |54   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |84   |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |115  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |144  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |172  |\n",
      "|{2023-08-04 13:40:00, 2023-08-04 13:50:00}|2113 |189  |\n",
      "+------------------------------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql(\"select * from query_update \")\n",
    "    .filter(col('route') == '2113')\n",
    "    .show(n = 100, truncate = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26a33a47-2697-459b-8776-4d5f11491e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_append.stop()\n",
    "query_complete.stop()\n",
    "query_update.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40ffac-54fd-4708-8dbe-bc140204c449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
